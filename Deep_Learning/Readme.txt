Deep Learning
-------------

Geoffrey Hinton "The Godfather of Deep Leaning" done research in 80's.  

Mimic how the human brain "one of the most powerful tool in the world for learning" operates. 

Input Layer(starting point) -> Hidden Layer (Processing Layer) -> Output Layer(Prediction)

Multiple hidden layers -> Deep learning. 

Single hidden layer -> Shallow learning. 


The Input Layer
---------------

Contain inputs for single entity " X1: Name, X2: Age, X3: Salary, X4: Sex ".

The Output Layer
----------------

Could be -> contineous, categorical (multiple outputs) or banary

Weights
-------

This is how a neural network learned by adjusting them. Which signal is poor and which are important. 

The Neuron
----------

Neuron computes the weighted sum of all the input values (âˆ‘wixi). Then it applies activation function over the weighted sum. By end it decides the neuron passes/not passes. 

The Activation Function
-----------------------

1. Threshold Function: Kind of Binary (if x >= 0 -> 1 elseif x < 0 -> 0)

2. The Sigmoid Function: Specialy useful in output layers if predicting probabilities. 

3. The Rectifier Function: Most popular for neural networks. From 0 to input value gradually progresses. 

4. Hyperbolic Tangent Function: Simillar to Sigmoid function but it will go below zero (-1 -> 0 -> 1).

How do NNs Work
---------------


